#  Neural Network from Scratch - Forward Propagation Only

This project demonstrates how a simple feedforward neural network works, implemented entirely from scratch in Python **without using any deep learning libraries like TensorFlow or PyTorch**.

###  What It Does
- Implements forward propagation step-by-step
- Uses sigmoid activation functions
- Supports multiple layers and neurons
- Demonstrates how inputs flow through a network to produce outputs

###  What It Does NOT Do
- No backpropagation (i.e., the network doesn't learn from data)
- No gradient descent or weight updates

This is purely an educational project to understand the **core mechanics of the forward pass** in neural networks.

###  Why This Project?
Most tutorials use high-level libraries that hide what's going on under the hood. This project is for learners who want to understand:
- How the forward pass works
- What happens layer by layer
- How activations are calculated manually

